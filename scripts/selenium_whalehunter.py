"""
WhaleHunter Selenium Scraper
Browser'Ä± otomatik aÃ§Ä±p whale verilerini Ã§eker
"""
import asyncio
import json
import time
from pathlib import Path
import sys
import os
from dotenv import load_dotenv

# Proje root'unu path'e ekle
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

from loguru import logger

try:
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.chrome.service import Service
    from webdriver_manager.chrome import ChromeDriverManager
except ImportError:
    logger.error("âŒ Selenium kurulu deÄŸil! YÃ¼klemek iÃ§in: pip install selenium webdriver-manager")
    sys.exit(1)

class WhaleHunterSeleniumScraper:
    """
    Selenium ile WhaleHunter'dan veri Ã§ek
    """
    
    def __init__(self, email: str, password: str):
        self.email = email
        self.password = password
        self.base_url = "https://whalehunterapp.com"
        self.driver = None
        
    def setup_driver(self):
        """
        Chrome WebDriver'Ä± hazÄ±rla (otomatik ChromeDriver indirme)
        """
        logger.info("ğŸŒ Chrome WebDriver baÅŸlatÄ±lÄ±yor...")
        
        chrome_options = Options()
        # chrome_options.add_argument("--headless")  # GÃ¶rÃ¼nmez mod (test iÃ§in kapalÄ±, gÃ¶rmek iÃ§in yorum satÄ±rÄ±)
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")  # Bot tespitini engelle
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # WebDriver'Ä± baÅŸlat (otomatik ChromeDriver yÃ¶netimi)
        try:
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            logger.info("âœ… Chrome baÅŸlatÄ±ldÄ±")
        except Exception as e:
            logger.error(f"âŒ Chrome baÅŸlatma hatasÄ±: {e}")
            logger.info("ğŸ’¡ Chrome browser kurulu mu? YÃ¼klemek iÃ§in: https://www.google.com/chrome/")
            raise
    
    def login(self):
        """
        WhaleHunter'a giriÅŸ yap
        """
        logger.info(f"ğŸ” Login: {self.email}")
        
        try:
            # Login sayfasÄ±na git
            self.driver.get(f"{self.base_url}/login")
            time.sleep(2)
            
            # Email input
            email_input = WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.NAME, "email"))
            )
            email_input.send_keys(self.email)
            
            # Password input
            password_input = self.driver.find_element(By.NAME, "password")
            password_input.send_keys(self.password)
            
            # Login button
            login_button = self.driver.find_element(By.CSS_SELECTOR, "button[type='submit']")
            login_button.click()
            
            # YÃ¶nlenmeyi bekle
            time.sleep(5)
            
            # BaÅŸarÄ±lÄ± mÄ± kontrol et
            current_url = self.driver.current_url
            logger.info(f"ğŸ“ YÃ¶nlendirilen URL: {current_url}")
            
            # Fees sayfasÄ±na gittiyse, Ã¼yelik gerekiyor demektir
            if "/fees" in current_url:
                logger.warning("âš ï¸  /fees sayfasÄ±na yÃ¶nlendirildi - WhaleHunter PRO Ã¼yeliÄŸi gerekli olabilir")
                logger.info("ğŸ’¡ Ama yine de binance-futures sayfasÄ±nÄ± kontrol edelim...")
                return True  # Devam et, belki veri gÃ¶rebiliriz
            
            if "/binance-futures" in current_url or "/dashboard" in current_url or "/login" not in current_url:
                logger.info("âœ… Login baÅŸarÄ±lÄ±!")
                return True
            else:
                logger.error(f"âŒ Login baÅŸarÄ±sÄ±z. URL: {current_url}")
                # Screenshot al
                screenshot_path = Path(project_root) / "data" / "login_error.png"
                self.driver.save_screenshot(str(screenshot_path))
                logger.info(f"ğŸ“¸ Screenshot kaydedildi: {screenshot_path}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Login hatasÄ±: {e}")
            return False
    
    def go_to_futures_page(self):
        """
        Binance Futures sayfasÄ±na git
        """
        logger.info("ğŸ“Š Binance Futures sayfasÄ±na gidiliyor...")
        
        try:
            self.driver.get(f"{self.base_url}/binance-futures")
            time.sleep(5)  # SayfanÄ±n yÃ¼klenmesini bekle
            
            logger.info("âœ… Binance Futures sayfasÄ± yÃ¼klendi")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Sayfa yÃ¼kleme hatasÄ±: {e}")
            return False
    
    def wait_for_data(self, duration_seconds: int = 30):
        """
        Whale verilerinin gelmesini bekle
        
        Args:
            duration_seconds: KaÃ§ saniye beklenecek
        """
        logger.info(f"â±ï¸  {duration_seconds} saniye boyunca whale verileri bekleniyor...")
        logger.info("ğŸ’¡ DataTable'da veri gÃ¶rÃ¼nmeye baÅŸladÄ±ÄŸÄ±nda otomatik olarak Ã§ekilecek\n")
        
        whale_data = []
        start_time = time.time()
        last_row_count = 0
        
        try:
            while time.time() - start_time < duration_seconds:
                try:
                    # DataTable'daki satÄ±rlarÄ± bul
                    table = self.driver.find_element(By.ID, "example")
                    tbody = table.find_element(By.TAG_NAME, "tbody")
                    rows = tbody.find_elements(By.TAG_NAME, "tr")
                    
                    # "No data available" kontrolÃ¼
                    if len(rows) == 1:
                        first_cell = rows[0].find_element(By.TAG_NAME, "td")
                        if "No data available" in first_cell.text:
                            logger.debug(f"â³ HenÃ¼z veri yok... ({int(time.time() - start_time)}s)")
                            time.sleep(2)
                            continue
                    
                    # Yeni veri var mÄ±?
                    current_row_count = len(rows)
                    if current_row_count > last_row_count:
                        logger.info(f"ğŸ“Š {current_row_count - last_row_count} yeni whale sinyali tespit edildi!")
                        last_row_count = current_row_count
                    
                    # Her satÄ±rÄ± parse et
                    for row in rows:
                        try:
                            cells = row.find_elements(By.TAG_NAME, "td")
                            
                            if len(cells) >= 11:  # En az 11 sÃ¼tun olmalÄ±
                                whale_entry = {
                                    'time': cells[0].text,
                                    'count': cells[1].text,
                                    'symbol': cells[2].text,
                                    'last_price': cells[3].text,
                                    'percent': cells[4].text,
                                    'change_24h': cells[5].text,
                                    'total_usdt': cells[6].text,
                                    'signal_type': cells[7].text,  # LONG/SHORT
                                    'long_usdt': cells[8].text,
                                    'short_usdt': cells[9].text,
                                    'strength': cells[10].text,  # Low/Medium/High
                                }
                                
                                # Duplicate kontrolÃ¼
                                if whale_entry not in whale_data:
                                    whale_data.append(whale_entry)
                                    
                                    # Konsola yazdÄ±r
                                    logger.info(f"""
ğŸ‹ YENÄ° WHALE SÄ°NYALÄ°:
   Symbol: {whale_entry['symbol']}
   Type: {whale_entry['signal_type']}
   Price: {whale_entry['last_price']}
   Strength: {whale_entry['strength']}
   Volume: {whale_entry['total_usdt']}
   24h: {whale_entry['change_24h']}
                                    """)
                        
                        except Exception as e:
                            logger.debug(f"SatÄ±r parse hatasÄ±: {e}")
                            continue
                    
                    time.sleep(2)  # 2 saniye bekle
                    
                except Exception as e:
                    logger.debug(f"Tablo okuma hatasÄ±: {e}")
                    time.sleep(2)
                    continue
            
            logger.info(f"\nâœ… Toplam {len(whale_data)} whale sinyali toplandÄ±")
            return whale_data
            
        except KeyboardInterrupt:
            logger.info("\nâ¹ï¸  KullanÄ±cÄ± tarafÄ±ndan durduruldu")
            return whale_data
    
    def capture_network_traffic(self):
        """
        Browser'Ä±n network trafiÄŸini yakala (WebSocket, XHR)
        """
        logger.info("ğŸ” Network trafiÄŸi yakalanÄ±yor...")
        
        # Chrome DevTools Protocol kullan
        logs = self.driver.get_log('performance')
        
        websocket_urls = []
        api_endpoints = []
        
        for entry in logs:
            log = json.loads(entry['message'])['message']
            
            if 'Network.webSocketCreated' in log.get('method', ''):
                ws_url = log['params']['url']
                websocket_urls.append(ws_url)
                logger.info(f"ğŸ”Œ WebSocket bulundu: {ws_url}")
            
            elif 'Network.requestWillBeSent' in log.get('method', ''):
                url = log['params']['request']['url']
                if 'api' in url or 'data' in url or 'signal' in url:
                    if url not in api_endpoints:
                        api_endpoints.append(url)
                        logger.info(f"ğŸ“¡ API endpoint: {url}")
        
        return {
            'websockets': websocket_urls,
            'api_endpoints': api_endpoints
        }
    
    def close(self):
        """
        Browser'Ä± kapat
        """
        if self.driver:
            logger.info("ğŸ”’ Browser kapatÄ±lÄ±yor...")
            self.driver.quit()

def main():
    email = os.getenv("WHALEHUNTER_EMAIL")
    password = os.getenv("WHALEHUNTER_PASSWORD")
    
    if not email or not password:
        logger.error("âŒ .env dosyasÄ±nda WHALEHUNTER_EMAIL ve WHALEHUNTER_PASSWORD gerekli!")
        return
    
    scraper = WhaleHunterSeleniumScraper(email, password)
    
    try:
        # 1. Browser'Ä± baÅŸlat
        scraper.setup_driver()
        
        # 2. Login
        if not scraper.login():
            return
        
        # 3. Futures sayfasÄ±na git
        if not scraper.go_to_futures_page():
            return
        
        # 4. Network trafiÄŸini yakala (opsiyonel)
        # network_info = scraper.capture_network_traffic()
        
        # 5. Whale verilerini bekle (30 saniye)
        whale_data = scraper.wait_for_data(duration_seconds=60)
        
        # 6. Verileri kaydet
        if whale_data:
            output_dir = Path(project_root) / "data"
            output_dir.mkdir(exist_ok=True)
            
            output_file = output_dir / "whalehunter_selenium_data.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(whale_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"\nğŸ’¾ Veriler kaydedildi: {output_file}")
            
            # Ä°statistikler
            logger.info("\nğŸ“Š Ä°STATÄ°STÄ°KLER:")
            logger.info(f"Toplam sinyal: {len(whale_data)}")
            
            # Signal type daÄŸÄ±lÄ±mÄ±
            long_count = sum(1 for w in whale_data if 'LONG' in w.get('signal_type', '').upper())
            short_count = sum(1 for w in whale_data if 'SHORT' in w.get('signal_type', '').upper())
            
            logger.info(f"LONG:  {long_count}")
            logger.info(f"SHORT: {short_count}")
        else:
            logger.warning("âš ï¸  HiÃ§ whale verisi alÄ±namadÄ±")
            logger.info("ğŸ’¡ Muhtemelen ÅŸu an piyasada bÃ¼yÃ¼k hareket yok")
        
    except Exception as e:
        logger.error(f"âŒ Hata: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        scraper.close()

if __name__ == "__main__":
    main()
